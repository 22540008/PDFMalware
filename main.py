# main.py

import streamlit as st
import pandas as pd
import requests
import io
from io import BytesIO
from feature_extraction import extract_features, save_features_to_csv
import os
import fitz  # PyMuPDF


import numpy as np
# import joblib
# import PyPDF2

# import re
# import nltk
# from nltk.corpus import stopwords
# from nltk.stem import PorterStemmer
# from nltk.tokenize import word_tokenize
# import string
import seaborn as sns
import warnings
# import base64
# import time

from PIL import Image
import matplotlib.pyplot as plt
warnings.filterwarnings('ignore')

st.sidebar.header('User Input Features')
uploaded_file = st.sidebar.file_uploader("Upload your input PDF file", type=["pdf"])
selected_page_count = st.sidebar.slider("Select number of pages to display", min_value=1, max_value=20, value=5)

# Variable to check if the feature extraction code has been loaded
feature_code_loaded = False
pdf_data_loaded = False


# @st.cache
@st.cache_data(ttl=3600)  # Set a time-to-live (ttl) value in seconds, adjust as needed
def load_pdf_features_from_github():
    # Load features extraction code from GitHub
    response = requests.get("https://raw.githubusercontent.com/22540008/PDFMalware/main/feature_extraction.py")
    return response.text
    # exec(response.text)
    # # Set the global variable to True to indicate that the code has been loaded
    # global feature_code_loaded
    # feature_code_loaded = True

# def load_pdf(uploaded_file):
#     pdf_content = uploaded_file.read()

#     # Check if the PDF content is empty
#     if not pdf_content:
#         st.error("The uploaded PDF file is empty.")
#         return ""

#     # Save the PDF content to a temporary file
#     temp_dir = "temp"
#     os.makedirs(temp_dir, exist_ok=True)
#     temp_pdf_path = os.path.join(temp_dir, "temp_pdf.pdf")
#     with open(temp_pdf_path, "wb") as temp_pdf_file:
#         temp_pdf_file.write(pdf_content)

#     return temp_pdf_path  # Return the path instead of text

def load_pdf(uploaded_file):
    pdf_content = uploaded_file.read()

    # Check if the PDF content is empty
    if not pdf_content:
        st.error("The uploaded PDF file is empty.")
        return ""

    # Save the PDF content to a temporary file
    temp_dir = "temp"
    os.makedirs(temp_dir, exist_ok=True)
    temp_pdf_path = os.path.join(temp_dir, "temp_pdf.pdf")
    with open(temp_pdf_path, "wb") as temp_pdf_file:
        temp_pdf_file.write(pdf_content)

    return temp_pdf_path  # Return the path instead of text


def load_data(pdf_path, selected_page_count):
    try:
        # Open the temporary PDF file using PyMuPDF
        doc = fitz.open(pdf_path)

        # Initialize a dictionary to store metadata and text
        pdf_info = {"metadata": doc.metadata, "pages": []}

        # Iterate through pages in the document
        for page_number in range(min(selected_page_count, doc.page_count)):
            page = doc[page_number]
            # Append the text of each page to the 'pages' list
            pdf_info["pages"].append(page.get_text())

        # Close the PDF document
        doc.close()

        return pdf_info
    except fitz.fitz.EmptyFileError:
        st.error("Cannot open empty document. The uploaded PDF file is empty.")
        return ""


def save_uploaded_file(uploaded_file):
    # Ensure the 'temp' directory exists
    temp_dir = "temp"
    os.makedirs(temp_dir, exist_ok=True)

    # Save the uploaded file to a temporary location
    pdf_path = os.path.join(temp_dir, uploaded_file.name)
    with open(pdf_path, "wb") as f:
        f.write(uploaded_file.read())  # Use read() instead of getvalue()
    return pdf_path

def main():
    lobal feature_code_loaded, pdf_data_loaded  # Use the global variables
    
    st.title("PDF Analysis App")
    uploaded_file = st.file_uploader("Upload a PDF file", type=["pdf"])
    if uploaded_file is not None:
        # Check if the feature extraction code has been loaded
        if not feature_code_loaded:
            # Load features extraction code from GitHub if not already loaded
            load_pdf_features_from_github()
            feature_code_loaded = True

        # Save the uploaded file to a temporary location
        pdf_path = save_uploaded_file(uploaded_file)

        # Extract features from the PDF content
        features_df = extract_features(pdf_path)

        # Display the results
        st.dataframe(features_df)

        # Load the PDF content including metadata and text
        pdf_info = load_data(pdf_path, selected_page_count)

        # Display the extracted text and metadata
        if pdf_info:
            st.text("PDF Metadata:")
            st.json(pdf_info["metadata"])

            st.text("Extracted Text:")
            for page_text in pdf_info["pages"]:
                st.text(page_text)

            # Save features to CSV (Optional)
            save_features_to_csv(features_df, "output.csv")

if __name__ == "__main__":
    main()
