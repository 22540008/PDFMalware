# main.py

import streamlit as st
import pandas as pd
import requests
from io import BytesIO
from feature_extraction import extract_features, save_features_to_csv
import os

import numpy as np
# import joblib
import PyPDF2

# import re
# import nltk
# from nltk.corpus import stopwords
# from nltk.stem import PorterStemmer
# from nltk.tokenize import word_tokenize
# import string
import seaborn as sns
import warnings
# import base64
# import time
# import io
from PIL import Image
import matplotlib.pyplot as plt
warnings.filterwarnings('ignore')

# nltk.download('stopwords')
# nltk.download('punkt')
# nltk.download('wordnet')
# nltk.download('averaged_perceptron_tagger')

st.sidebar.header('User Input Features')
uploaded_file = st.sidebar.file_uploader("Upload your input PDF file", type=["pdf"])

@st.cache
def load_pdf_features_from_github(pdf_path):
    # Load features extraction code from GitHub
    response = requests.get("https://github.com/22540008/PDFMalware/blob/main/feature_extraction.py")
    exec(response.text)

# def load_pdf(uploaded_file):
#     pdfFileObj = open(uploaded_file, 'rb')
#     pdfReader = PyPDF2.PdfFileReader(pdfFileObj)
#     pageObj = pdfReader.getPage(0)
#     return pageObj.extractText()

# def load_pdf(file_path):
#     pdfFileObj = open(file_path, 'rb')
#     pdfReader = PyPDF2.PdfReader(pdfFileObj)
#     pageObj = pdfReader.getPage(0)
#     return pageObj.extractText()

# def load_pdf(uploaded_file):
    # pdfFileObj = BytesIO(uploaded_file.read())
    # pdfReader = PyPDF2.PdfFileReader(pdfFileObj)
    # pageObj = pdfReader.getPage(0)
    # return pageObj.extractText()

# def load_data(uploaded_file):
#     text = load_pdf(uploaded_file)
#     # text = load_pdf(uploaded_file.name)
#     return text

def load_pdf(uploaded_file):
    pdfFileObj = BytesIO(uploaded_file.read())
    pdfReader = PyPDF2.PdfFileReader(pdfFileObj)
    pageObj = pdfReader.getPage(0)
    return pageObj.extractText()

def load_data(uploaded_file):
    text = load_pdf(uploaded_file)
    return text

def save_uploaded_file(uploaded_file):
    # Ensure the 'temp' directory exists
    temp_dir = "temp"
    os.makedirs(temp_dir, exist_ok=True)

    # Save the uploaded file to a temporary location
    pdf_path = os.path.join(temp_dir, uploaded_file.name)
    with open(pdf_path, "wb") as f:
        f.write(uploaded_file.read())  # Use read() instead of getvalue()
    return pdf_path

def main():
    st.title("PDF Analysis App")
    uploaded_file = st.file_uploader("Upload a PDF file", type=["pdf"])
    if uploaded_file is not None:
        # Save the uploaded file to a temporary location
        pdf_path = save_uploaded_file(uploaded_file)

        # Load the PDF text
        text = load_pdf(uploaded_file)
        st.text("Extracted Text:")
        st.text(text)

        
        # Load features extraction code from GitHub
        load_pdf_features_from_github(pdf_path)

        # Extract features
        features_df = extract_features(pdf_path)

        # Display the results
        st.dataframe(features_df)

        # Save features to CSV (Optional)
        save_features_to_csv(features_df, "output.csv")

if __name__ == "__main__":
    main()
